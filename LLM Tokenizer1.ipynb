{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGrTOOZWgzb2"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers==4.41.2 sentence-transformers==3.0.1 gensim==4.3.2 scikit-learn==1.5.0 accelerate==0.31.0 peft==0.11.1 scipy==1.10.1 numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84ZfEGglg7UQ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=False,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ddhFyZpig_dq"
      },
      "outputs": [],
      "source": [
        "prompt = \"Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.<|assistant|>\"\n",
        "# Tokenize the input prompt\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids  # no .to(\"cuda\")\n",
        "\n",
        "# Generate the text\n",
        "generation_output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_new_tokens=20,   # enough to generate a full email\n",
        "          # optional: controls randomness\n",
        ")\n",
        "\n",
        "# Print the output\n",
        "print(tokenizer.decode(generation_output[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll2co4_XhOVK"
      },
      "outputs": [],
      "source": [
        "print(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx2s09uzhO75"
      },
      "outputs": [],
      "source": [
        "for id in input_ids[0]:\n",
        "   print(tokenizer.decode(id))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_output"
      ],
      "metadata": {
        "id": "PC7hxx3irp0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(3323))\n",
        "print(tokenizer.decode(622))\n",
        "print(tokenizer.decode([3323, 622]))\n",
        "print(tokenizer.decode(29901))"
      ],
      "metadata": {
        "id": "fipEk5jRrqRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bXkNotwssukv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0oCP6EkVu+xqwKyaOK+zw"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}