{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRd7rzuvH+oKaW41v5mrXd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1wS3GcXs-U2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "colors_list = [\n",
        "    '102;194;165', '252;141;98', '141;160;203',\n",
        "    '231;138;195', '166;216;84', '255;217;47'\n",
        "]\n",
        "\n",
        "def show_tokens(sentence, tokenizer_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    token_ids = tokenizer(sentence).input_ids\n",
        "    for idx, t in enumerate(token_ids):\n",
        "        print(\n",
        "            f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n",
        "            tokenizer.decode(t) +\n",
        "            '\\x1b[0m',\n",
        "            end=' '\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "English and CAPITALIZATION\n",
        "ðŸŽµ é¸Ÿ\n",
        "show_tokens False None elif == >= else: two tabs:\"    \" Three tabs: \"       \"\n",
        "12.0*50=600\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "m2C6wi3OyA3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face"
      ],
      "metadata": {
        "id": "_AvDEIIrzrOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)"
      ],
      "metadata": {
        "id": "uyZGVQ7k0JhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "unmasker(\"Hello I'm a [MASK] model.\")\n",
        "\n",
        "[{'sequence': \"[CLS] hello i'm a fashion model. [SEP]\",\n",
        "  'score': 0.1073106899857521,\n",
        "  'token': 4827,\n",
        "  'token_str': 'fashion'},\n",
        " {'sequence': \"[CLS] hello i'm a role model. [SEP]\",\n",
        "  'score': 0.08774490654468536,\n",
        "  'token': 2535,\n",
        "  'token_str': 'role'},\n",
        " {'sequence': \"[CLS] hello i'm a new model. [SEP]\",\n",
        "  'score': 0.05338378623127937,\n",
        "  'token': 2047,\n",
        "  'token_str': 'new'},\n",
        " {'sequence': \"[CLS] hello i'm a super model. [SEP]\",\n",
        "  'score': 0.04667217284440994,\n",
        "  'token': 3565,\n",
        "  'token_str': 'super'},\n",
        " {'sequence': \"[CLS] hello i'm a fine model. [SEP]\",\n",
        "  'score': 0.027095865458250046,\n",
        "  'token': 2986,\n",
        "  'token_str': 'fine'}]"
      ],
      "metadata": {
        "id": "31qcEMQCy0vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "CeKfs_wQ06Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"bert-base-cased\")"
      ],
      "metadata": {
        "id": "7xUSxfcj07-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rlPp_rX71DD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}