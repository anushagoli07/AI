{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPfXM5dG/pq07FeqWboCmVl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic datasets openai datamapplot"
      ],
      "metadata": {
        "id": "UzrQIt6Y1It6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from huggingface\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"maartengr/arxiv_nlp\")[\"train\"]\n",
        "\n",
        "# Extract metadata\n",
        "abstracts = list(dataset[\"Abstracts\"])\n",
        "titles = list(dataset[\"Titles\"])"
      ],
      "metadata": {
        "id": "caPq-6eS1JHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Create an embedding for each abstract\n",
        "embedding_model = SentenceTransformer('thenlper/gte-small')\n",
        "embeddings = embedding_model.encode(abstracts, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "dwsDTG9v1O8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Create an embedding for each abstract\n",
        "embedding_model = SentenceTransformer('thenlper/gte-small')\n",
        "embeddings = embedding_model.encode(abstracts, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "DIm4dvL21PeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from umap import UMAP\n",
        "\n",
        "# We reduce the input embeddings from 384 dimenions to 5 dimenions\n",
        "umap_model = UMAP(\n",
        "    n_components=5, min_dist=0.0, metric='cosine', random_state=42\n",
        ")\n",
        "reduced_embeddings = umap_model.fit_transform(embeddings)"
      ],
      "metadata": {
        "id": "kL7ChvRM82AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hdbscan import HDBSCAN\n",
        "\n",
        "# We fit the model and extract the clusters\n",
        "hdbscan_model = HDBSCAN(\n",
        "    min_cluster_size=50, metric='euclidean', cluster_selection_method='eom'\n",
        ").fit(reduced_embeddings)\n",
        "clusters = hdbscan_model.labels_\n"
      ],
      "metadata": {
        "id": "RyUfR_Lm1Tjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "# Train our model with our previously defined models\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=embedding_model,\n",
        "    umap_model=umap_model,\n",
        "    hdbscan_model=hdbscan_model,\n",
        "    verbose=True\n",
        ").fit(abstracts, embeddings)"
      ],
      "metadata": {
        "id": "ruATTA331XO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topic_differences(model, original_topics, nr_topics=5):\n",
        "    \"\"\"Show the differences in topic representations between two models \"\"\"\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(columns=[\"Topic\", \"Original\", \"Updated\"])\n",
        "    for topic in range(nr_topics):\n",
        "\n",
        "        # Extract top 5 words per topic per model\n",
        "        og_words = \" | \".join(list(zip(*original_topics[topic]))[0][:5])\n",
        "        new_words = \" | \".join(list(zip(*model.get_topic(topic)))[0][:5])\n",
        "        df.loc[len(df)] = [topic, og_words, new_words]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "j1jfxqMg1ka_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from bertopic.representation import TextGeneration\n",
        "from copy import deepcopy\n",
        "\n",
        "prompt = \"\"\"I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "\n",
        "The topic is described by the following keywords: '[KEYWORDS]'.\n",
        "\n",
        "Based on the documents and keywords, what is this topic about?\"\"\"\n",
        "\n",
        "# Save original representations\n",
        "original_topics = deepcopy(topic_model.topic_representations_)\n",
        "\n",
        "# Update our topic representations using Flan-T5\n",
        "generator = pipeline('text-generation', model='google/flan-t5-small')\n",
        "representation_model = TextGeneration(\n",
        "    generator, prompt=prompt, doc_length=50, tokenizer=\"whitespace\"\n",
        ")\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# Show topic differences\n",
        "topic_differences(topic_model, original_topics)"
      ],
      "metadata": {
        "id": "Tm2M98Hv_GHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34RrWCk7SROo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}